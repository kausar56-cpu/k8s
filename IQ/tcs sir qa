What happens when you do SSHTo your server ?
SSH connects my client to the server on port 22, authenticates with key/password, 
establishes encryption, and then gives me a secure shell to run commands.
-----------------------------------------------------------------------------------

1) Your application on EC2 experiences traffic spikes only during business hours. How would you optimize cost and performance?

‚ÄúI will use Auto Scaling for EC2 so that more instances run only in business hours 
and scale down after hours. Also, I can use a Load Balancer for even traffic distribution.
For more cost saving, I can use Spot Instances or Scheduled Scaling.‚Äù
----------------------------------------------------------------------------------------
2) Your EC2 instance crashed unexpectedly. What steps would
you take to identify the issue and restore service quickly?
If my EC2 instance crashes, first I would check system logs and CloudWatch metrics to find the cause (like CPU, memory, or disk).
Next, I‚Äôd try to quickly restore service by restarting the instance or replacing it with a new one using an AMI or Auto Scaling.
After recovery, I‚Äôd analyze root cause, such as application errors or OS issues, and put preventive measures in place like monitoring and alerts.‚Äù
-----------------------------------------------------------------------------------------------------------------------------------------
3) You have deployed your app on EC2 instance. The app has to Fetch some images
from internet but it's not able to fetch. What might be the possible issues?

If my app on EC2 can‚Äôt fetch images from the internet, I would first check if the instance has internet access. 
If it‚Äôs in a private subnet, I‚Äôd verify NAT Gateway. Then, I‚Äôd check security group outbound rules for ports 
80/443 and confirm that NACLs allow return traffic.
I‚Äôd also test DNS resolution and ensure no local firewall is blocking traffic. These steps usually help 
identify and fix the issue quickly.
----------------------------------------------------------------------------------------------
4) You accidentally deleted data from S3. How do you recover it?

If I accidentally delete data from S3, the first thing I check is whether S3 Versioning is enabled.
If it is, I can easily recover the object by restoring a previous version. If Cross-Region Replication was set up,
I can also restore it from the replicated bucket. If versioning wasn‚Äôt enabled, unfortunately, the data cannot be 
recovered, but I‚Äôd analyze the CloudTrail logs
to identify the cause and immediately enable Versioning and MFA Delete to prevent such incidents in the future."
---------------------------------------------------------------------------------------------------------
6) I have 2 EC2 Instance in 2 VPC one in each. First one is running
frontend app and second is running backend. These 2 app needs to
communicate but they're not able to communicate. How will you fix this ?

‚ÄúSince the two EC2s are in different VPCs, they can‚Äôt communicate directly.
I would enable communication either by creating a VPC peering connection or using a Transit Gateway. 
Then, I‚Äôd update the route tables and security groups to allow traffic between the frontend and backend subnets.‚Äù
----------------------------------------------------------------------------------------------------------

7) I have an app running on EC2. Product icons are stored in S3 bucket which
Needs to be shown on web home page. When my application is trying to fetch
it's resulting into error. What might be the problem here?

I will check bucket policy and ensure objects are accessible either via pre-signed URLs or correct IAM role. If the frontend directly
loads icons, I‚Äôll configure proper CORS policy on the S3 bucket. Also, if private access is required, I‚Äôll set up an S3 VPC endpoint.‚Äù
-----------------------------------------------------------------------------------------------------------------------------------------

10) how to distribute 10 pods equally over 10 nodes in Kubernetes?
Like for log collecting metric beat, dynatrace agent etc

To distribute one pod per node, I‚Äôll use a DaemonSet. It ensures that exactly one pod of my app runs on each node, 
which is ideal for log collectors or monitoring agents like metricbeat and dynatrace."

---------------------------------------------------------------------------------------------------------------------

13) I have created a VPC manually. Now I have to create one EC2 instance
using Terraform. How will you pass VPC id here in Terraform script?

If the VPC is created manually, Terraform doesn‚Äôt track it, so I would pass the VPC ID as a variable in my script, 
or use a data block to fetch the existing VPC by its tags. This way Terraform can still provision the EC2 instance inside that VPC.‚Äù

data "aws_vpc" "my_vpc" {
  filter {
    name   = "tag:Name"
    values = ["my-manual-vpc"]
  }
}

resource "aws_instance" "my_ec2" {
  ami           = "ami-1234567890abcdef0"
  instance_type = "t2.micro"
  subnet_id     = "subnet-xxxxxx"
  vpc_security_group_ids = [aws_security_group.my_sg.id]
  tags = {
    Name = "MyEC2"
  }
}
-----------------------------------------------------------------------------------------------------
14) You have provisioned a VPC using Terraform and someone deleted
it manually. Now if you run Terraform apply, how will your pipeline behave?

If someone deletes the VPC manually, Terraform will detect this as a drift in the infrastructure state during the plan phase.
Since the VPC is missing, Terraform will show that the resource needs to be created again.
When I run terraform apply, it will re-create the VPC according to the configuration defined in my .tf files." ‚úÖ
-----------------------------------------------------------------------------------------------------------------------

15) I have 2 modules written one for VPC and second for EC2. EC2 modules need VPC id
to provision. How will you ensure that EC2 module get VPC id at runtime?

I will use module outputs to export the VPC ID from the VPC module and pass it as an input variable to the EC2 module. 
Terraform automatically handles dependencies and ensures the correct order of resource creation.
----------------------------------------------------------------------------------------------------------------

17) I am trying to run one script file on my Linux server and
getting permission error. How will you troubleshoot this ?

If I get a permission error while running a script, first I‚Äôll check if the file has execute permission 
(chmod +x). Then I‚Äôll verify ownership and whether I‚Äôm running it correctly with ./script.sh or bash script.sh. 
If it‚Äôs copied from Windows,
I‚Äôll fix line endings using dos2unix. Finally, if SELinux is enabled, I‚Äôll check for security restrictions.
----------------------------------------------------------------------------------------------------------------

18) Linux server is experiencing slow performance.
How will you debug this slowness?

For Linux server slowness, I will:

Check CPU, memory, and load using top, htop, or uptime.

Verify disk I/O and space with iostat, df -h.

Review logs (/var/log/) and network usage with netstat/ss
----------------------------------------------------------------------------

I have to deploy an application. In which scenario you will choose EC2 
and Lambda ?I have to deploy an application. In which scenario

If my application needs to run all the time, has complex setup, or requires full control over 
the server, I will choose EC2.But if my application has small tasks, runs only when triggered, and I want 
to save cost without managing servers, I will choose Lambda.‚Äù
---------------------------------------------------------------------------------------
How will you troubleshoot 403 error code?-----

A 403 error means forbidden ‚Äì the server understood the request but refused to allow it.
To troubleshoot, first I will check permissions. For example: in web servers I will check 
file/folder permissions, in S3 I will check bucket policy, in APIs I will check authentication 
and IAM roles. Then I verify if the user or service account has the correct access rights.
Finally, I review logs (web server logs, CloudTrail, or app logs) to see the exact reason.‚Äù
-------------------------------------------------------------------------------------

‚ÄúI manage my infrastructure using Infrastructure as Code with Terraform,
which keeps everything automated and version-controlled. Deployments are integrated through CI/CD pipelines in Jenkins, and I 
use Prometheus and Grafana for monitoring along with ELK stack for logging.
This ensures scalability, consistency, and easy troubleshooting.‚Äù

----------------------------------------------------------------------------------------------------------------------------------
What will happen if your infrastructure has been deleted manually
and
you run infra provisioning pipeline again ?

If infra is deleted manually, the pipeline will recreate it because Terraform compares actual state vs. 
desired state in code. As long as the state file is intact, 
infra will be provisioned back. But if the state file is also lost, Terraform may try to create duplicate resources.‚Äù
-------------------------------------------------------------------------------------------------------------------------------------

How will you push code from local to GitHub repository
You can answer in simple steps like this in interview:

First, initialize git in project ‚Üí git init.

Add remote GitHub repo ‚Üí git remote add origin <repo-URL>.

Stage and commit code ‚Üí git add . && git commit -m "Initial commit".

Push to GitHub ‚Üí git push origin main (or master). ‚úÖ
--------------------------------------------------------------------------------------------------------------------------
4) Suppose you have an EC2 Machine and you performed some task today.
Now you have to perform the same task tomorrow and so on
but on a new EC2 Machine. What will be the best way to do task here?

"I will never do the same task manually again and again. I‚Äôll automate it. Depending on the requirement:

For pre-baked configuration ‚Üí I‚Äôll use an AMI.

For startup scripts ‚Üí I‚Äôll use User Data.

For large-scale infra management ‚Üí I‚Äôll use Terraform with Ansible so that every time a new EC2 is launched, tasks are performed automatically."
----------------------------------------------------------------------------------------------------------------------------
6) In S3 bucket, I want to keep my bucket private and at the same time
I want my one of object can be fetched by one user for specific 15 mins.
How to achieve this ?

"I will keep my bucket private and use an S3 Pre-Signed URL to share the object. 
The Pre-Signed URL can be generated through AWS CLI or SDK, and I will set the expiry to 15 minutes.
After that time, the link won‚Äôt work anymore. This ensures the bucket is private, but still allows controlled access when needed."
---------------------------------------------------------------------------------------------------------------------------------------

18) Which AWS services can be used to trigger notification whenever
your database storage gets consumed more than 80%?

"I‚Äôll configure a CloudWatch alarm on the database‚Äôs FreeStorageSpace metric. Once utilization crosses 80%, the alarm will trigger 
an SNS topic, which will send me a notification (email/SMS). This ensures proactive alerting before the database runs out of storage."
--------------------------------------------------------------------------------------------------------








--------------------------------------------------------------------------
‚úÖ What is terraform taint?
terraform taint ‡§Æ‡•ç‡§π‡§£‡§ú‡•á:
üëâ ‡§è‡§ï‡§æ resource ‡§≤‡§æ ‡§ñ‡§∞‡§æ‡§¨ (bad) ‡§Æ‡•ç‡§π‡§£‡•Ç‡§® ‡§Æ‡§æ‡§∞‡•ç‡§ï ‡§ï‡§∞‡§£‡§Ç,
‡§ú‡•á‡§£‡•á‡§ï‡§∞‡•Ç‡§® Terraform ‡§™‡•Å‡§¢‡§ö‡•ç‡§Ø‡§æ ‡§µ‡•á‡§≥‡•Ä ‡§§‡•á delete ‡§ï‡§∞‡•Ç‡§® ‡§™‡§∞‡§§ create ‡§ï‡§∞‡•á‡§≤.

Sure! Here's the English translation:

---

## ‚úÖ What is `terraform taint`?

`terraform taint` means:
üëâ Marking a resource as **bad (unhealthy)**,
so that Terraform will **destroy and recreate it** during the next `terraform apply`.

========================================================================================================
=Mindmap
===========

1. may i know how you are deploying your application to kubernetes cluster ?
2. May i know the how ?

===========
Royal Cyber
===========

1.What r the types of volumes in docker ?
2.Difference betn persistent and mount bind volume in docker?
4.How will you push image to docker regisry from kubernetes cluster?
5.I am asking the mirror image 
3.How take back image that we recently lost? docker commit
4.In EBS what is the size oF block 10 gb of ebs volume?
5.Algorithm behind load balancer?

6.If there are 5 master node and 10 worker node is running and due to some issue 3 goes 
down could you tell me my k8s cluster will run of not?
7.How will you upgrade k8s cluster ?
8.Now lets take there is new user which is recently joined whose name is soham and i want to create that user and
\also i want create a role for him how can i do that?
9.which one is stable version in kubernetes?
10.k8s architecture?
11.In kubernetes how will you expose your application to external world so user can access it?
12.what is labels and selector?

13.How you can create a kubernetes cluster I am asking on on primise ?
14.In docker i have store the logs which is /var/etc/etc/dockerlog & because some issue if /etc2 folder is not working and you need make sure that this will not 
how will you do that like which you will change the loaction or like that type question could you gue which question he trying to asking ?
ANS*** 

======
CGI:
====== 
In linux I want to install a package by using sudo apt get install but its showing package not found how to do it ? apt get update -- apt-cache search <package_name>  
lets take example i want to scale my nginx conatiner in docker how can i achieve that ? 
docker swarm init -- docker service create --name nginx-service --replicas 1 -p 80:80 nginx -- docker service scale nginx-service=3


======
One2N:
====== 

CI CD is different in ur project ?
---------------------------------------------------------------------------------------------------------------------------------------------------------------
Did you do only one time jar file in maven in ci cd also you are doing it docker file ?

### **Question:** Do you build the JAR file only once in Maven during CI/CD, or do you also build it in the Dockerfile?  

‚úÖ **Answer:** The **JAR file should be built only once** in the CI/CD pipeline using Maven. In the Dockerfile, 
you should **copy** the pre-built JAR instead of building it again.  

### **Best Practice Approach** (CI/CD + Docker)  
1. **CI/CD Pipeline:**  
   - Build the JAR using Maven (`mvn package`).  
   - Store the JAR in an artifact repository (e.g., Nexus, Artifactory, or S3).  

2. **Dockerfile:**  
   - Use a multi-stage build **if necessary**, or just copy the pre-built JAR.  

### **Example Dockerfile (Copying Pre-built JAR)**  
```dockerfile
FROM openjdk:17-jdk-slim
WORKDIR /app
COPY target/myapp.jar myapp.jar  # ‚úÖ Copy pre-built JAR
CMD ["java", "-jar", "myapp.jar"]
```
üöÄ This ensures efficient builds and avoids rebuilding the JAR inside the Docker image.
------------------------------------------------------------------------------------------------------------------------------------------------------------------
How services wil communicate ? talk with each other in kubernetes ?
Could you tell me end to end setup for kubernetes cluster for ELK from scratch how its things works and how to implement?
-----------------------------------------------------------------------------------------------------------------------------------------------------------
In eks cluster How will you know that this the authentication is valid user ?

kubectl auth can-i create deployment ----> yes
kubectl auth can-i delete nodes ------> no
kubectl auth can-i create deployment --as dev-user ----> no
kubectl auth can-i create pods --as dev-user -----> yes
kubectl auth can-i create pods --as dev-user --namespace test ----> no
------------------------------------------------------------------------------------------------------------------------------------------------------------------
How to check port of services running in linux ?
what is the difference between demonset and replicaset ?
how will you set up elk from scratch for kubernetes nodes ?
How you setup basic setup for kibana using deployement file ? 
workflow of ELK ?
------------------------------------------------------------------------------------------------------------------------------------------------------------------
What is Nginx?
Nginx is a high-performance web server, reverse proxy, and load balancer. It is widely used for handling large amounts of traffic efficiently.

Key Features of Nginx:
‚úÖ Web Server ‚Äì Serves static and dynamic web pages
‚úÖ Reverse Proxy ‚Äì Forwards client requests to backend servers
‚úÖ Load Balancer ‚Äì Distributes traffic across multiple servers
‚úÖ Security ‚Äì Supports SSL/TLS, authentication, and rate limiting
‚úÖ Caching ‚Äì Improves website performance by storing frequently accessed content
--------------------------------------------------------------------------------------------------------------------------------------




=========
Deloitte:
=========
1. Could you give an introduction yourself and your daily activities as a DevOps engineer?
2. In Terraform, I‚Äôve created a database with sensitive information like a password, and I don't want it to appear in the output. How can I do that?

Sure! Here's a **3-line interview-style answer**:

> We manage secrets in Terraform using **AWS Secrets Manager** to keep them secure.
> Secrets are fetched using a `data` block and parsed with `jsondecode()` into `locals` for safe usage.
> This avoids hardcoding and ensures secrets stay hidden from logs and version control.

3
----------------------------------------------------------------------------------------------------------------------------------------------------------
4. In a Dockerfile, which user performs what action, and how can I specify the user ?

### **User Management in a Dockerfile: Detailed Explanation**  

By default, Docker containers run as the **root user**, which has full system privileges.
This can be a security risk. To improve security and control, Docker allows you to **specify a different user** using the `USER` instruction.

---

### **How to Specify a User in a Dockerfile?**  
You can define a user in the Dockerfile using the following steps:

1. **Create a New User** (if not already present).  
2. **Switch to that User** using the `USER` instruction.  

#### **Example: Running as a Non-Root User**
```dockerfile
# Use an official base image
FROM ubuntu:latest

# Create a new user 'myuser' and its home directory
RUN useradd -m myuser

# Switch to the new user
USER myuser

# Set the working directory for this user
WORKDIR /home/myuser

# Default command
CMD ["bash"]
```
‚úÖ Now, all commands run in the container will be executed as **`myuser`** instead of **`root`**.

---

### **Understanding Which User Performs What Action**
| **Action**                      | **User Responsible** |
|---------------------------------|----------------------|
| Install system packages         | **Root (Default)**   |
| Run application processes       | **Non-root user**    |
| Modify system files             | **Root user**        |
| Access user-specific files      | **Non-root user**    |

---

### **Why Use a Non-Root User in Docker?**
‚úÖ **Security** ‚Äì Reduces attack surface (if a hacker gains access, they won‚Äôt have root privileges).  
‚úÖ **Compliance** ‚Äì Some environments (e.g., Kubernetes, OpenShift) **enforce** running containers as non-root.  
‚úÖ **Best Practices** ‚Äì Prevents accidental system-wide changes in the container.

--------------------------------------------------------------------------------------------------------------------------------------------------------------
5. What are the different networking types in Docker ?
6. What is the difference between a bridge network and an overlay network in Docker ?
7. How does a user access an application deployed in a Kubernetes cluster? What is the process ?
8. Let‚Äôs say there‚Äôs an application deployed in AWS, and we want it to be highly available. How can we achieve high availability ?



-------------------------------------------------------------------------------------------------------------------------------------------------------------
9. In Terraform, there is a database password in my configuration. How can I ensure that the password does not appear in the output ? Which parameter should I use?
‡§™‡•ç‡§∞‡§∂‡•ç‡§®: Terraform ‡§Æ‡§ß‡•ç‡§Ø‡•á ‡§°‡•á‡§ü‡§æ‡§¨‡•á‡§∏‡§ö‡§æ ‡§™‡§æ‡§∏‡§µ‡§∞‡•ç‡§° ‡§Ü‡§â‡§ü‡§™‡•Å‡§ü‡§Æ‡§ß‡•ç‡§Ø‡•á ‡§¶‡§ø‡§∏‡•Ç ‡§®‡§Ø‡•á ‡§Ø‡§æ‡§∏‡§æ‡§†‡•Ä ‡§ï‡§æ‡§Ø ‡§ï‡§∞‡§æ‡§µ‡•á?
### **How to Hide Sensitive Data in Terraform Output?**  

To **prevent the database password** from appearing in Terraform output, use the **`sensitive`** argument.

### **Example: Marking a Variable as Sensitive**  
```hcl
variable "db_password" {
  description = "Database password"
  type        = string
  sensitive   = true   # ‚úÖ Hides the value in Terraform output
}
```

### **Example: Using `sensitive` in Outputs**  
```hcl
output "db_password" {
  value     = var.db_password
  sensitive = true   # ‚úÖ Ensures Terraform does not display this value
}
```

### **Alternative: Store Password Securely**
- Use **AWS Secrets Manager** or **HashiCorp Vault** instead of hardcoding passwords.  
- Use Terraform **`TF_VAR_db_password`** environment variable instead of storing it in code.  

Would you like a best-practice example for securing secrets in Terraform? üöÄ
----------------------------------------------------------------------------------------------------------------------------------------------------------------
10. What is the difference between SLO (Service Level Objective) and SLA (Service Level Agreement) ?

### **SLO vs. SLA: Key Differences**  

| **Aspect**               | **SLO (Service Level Objective)** | **SLA (Service Level Agreement)** |
|--------------------------|---------------------------------|----------------------------------|
| **Definition**           | A **target** for service reliability and performance | A **contract** between service provider and customer defining expectations |
| **Purpose**             | Internal goal for system uptime, latency, etc. | Legal agreement ensuring commitments to customers |
| **Enforcement**         | Not legally binding, used for monitoring and improvement | Legally binding, can lead to penalties if violated |
| **Example**             | "99.9% uptime goal for a service" | "99.9% uptime guaranteed, or customer gets a refund" |
| **Scope**               | Used by internal teams (SRE, DevOps) | Defined between service provider and customer |
| **Consequence of Breach** | Performance review, alerting | Financial penalties, refunds, or service credits |

### **Summary:**  
- **SLO** is an internal **goal** to measure service reliability.  
- **SLA** is a **formal agreement** with customers, including penalties if not met.  

--------------------------------------------------------------------------------------------------------------------------------------------------------
11. What is the difference between PV (Persistent Volume) and PVC (Persistent Volume Claim) ?
12. Explain the Kubernetes architecture used in your project.
13. Are you using stateful or stateless applications in your project ?
14. What is a StatefulSet in Kubernetes ?
15. Scenario-based questions related to PVC (Persistent Volume Claim) and PV (Persistent Volume).
16. How is a Persistent Volume (PV) created in Kubernetes?
17. What is a Persistent Volume (PV)?
18. What is the difference between a Persistent Volume (PV) and a Persistent Volume Claim (PVC) ?
19. How do you map ports in a Dockerfile ?
20. If there is one port 80 and another port 8000, how do you map them in Docker ?
21. What are the different services in Kubernetes, and which services have you worked on ?
22. Which ingress controller are you using in your project?
23. What is the difference between a rollback, a canary deployment, and a blue-green deployment in Kubernetes ?
24. Scenario-based questions related to deployments in Kubernetes.



-----------------------------------------------------------------------------------------------------------------------------------------------------
25. Let‚Äôs take a scenario: I am creating an EC2 instance and attaching it to a VPC. How can I ensure the VPC is created first and then the EC2 instance?
(Implicit Dependency)
What is a Direct Reference (Reference) in Terraform?
A direct reference in Terraform means using the output or attribute of one resource inside another resource directly.
This helps Terraform automatically understand the correct order of resource creation.

resource "aws_vpc" "my_vpc" {
  cidr_block = "10.0.0.0/16"
}

resource "aws_subnet" "my_subnet" {
  vpc_id     = aws_vpc.my_vpc.id  # VPC ‡§Ü‡§ß‡•Ä ‡§§‡§Ø‡§æ‡§∞ ‡§π‡•ã‡§à‡§≤ ‡§ï‡§æ‡§∞‡§£ Subnet ‡§§‡•ç‡§Ø‡§æ‡§ö‡§æ ‡§µ‡§æ‡§™‡§∞ ‡§ï‡§∞‡§§‡•á
  cidr_block = "10.0.1.0/24"
}

resource "aws_instance" "my_instance" {
  ami           = "ami-0abcdef1234567890"
  instance_type = "t2.micro"
  subnet_id     = aws_subnet.my_subnet.id  # Subnet ‡§§‡§Ø‡§æ‡§∞ ‡§ù‡§æ‡§≤‡•ç‡§Ø‡§æ‡§µ‡§∞‡§ö EC2 instance ‡§§‡§Ø‡§æ‡§∞ ‡§π‡•ã‡§à‡§≤
}


------------------------------------------------------------------------------------------------------------------------------------------------------
26. How do you ensure that a VPC is created before an EC2 instance in AWS using Terraform ?  
Terraform ‡§Æ‡§ß‡•ç‡§Ø‡•á EC2 ‡§∏‡•Å‡§∞‡•Ç ‡§ï‡§∞‡§£‡•ç‡§Ø‡§æ‡§Ü‡§ß‡•Ä VPC ‡§§‡§Ø‡§æ‡§∞ ‡§ï‡§∏‡•á ‡§∏‡•Å‡§®‡§ø‡§∂‡•ç‡§ö‡§ø‡§§ ‡§ï‡§∞‡§æ‡§µ‡•á?

Terraform ‡§Æ‡§ß‡•ç‡§Ø‡•á VPC ‡§§‡§Ø‡§æ‡§∞ ‡§ù‡§æ‡§≤‡•ç‡§Ø‡§æ‡§®‡§Ç‡§§‡§∞‡§ö EC2 ‡§∏‡•Å‡§∞‡•Ç ‡§π‡•ã‡§à‡§≤ ‡§Ø‡§æ‡§ö‡•Ä ‡§ñ‡§æ‡§§‡•ç‡§∞‡•Ä ‡§ï‡§∞‡§£‡•ç‡§Ø‡§æ‡§∏‡§æ‡§†‡•Ä ‡§ñ‡§æ‡§≤‡•Ä‡§≤ ‡§™‡§¶‡•ç‡§ß‡§§‡•Ä ‡§µ‡§æ‡§™‡§∞‡§§‡§æ ‡§Ø‡•á‡§§‡§æ‡§§:

1Ô∏è‚É£ ‡§Ö‡§™‡•ç‡§∞‡§§‡•ç‡§Ø‡§ï‡•ç‡§∑ ‡§Ö‡§µ‡§≤‡§Ç‡§¨‡§ø‡§§‡•ç‡§µ (Implicit Dependency) ‚Äì ‡§∏‡§∞‡•ç‡§µ‡•ã‡§§‡•ç‡§§‡§Æ ‡§™‡§¶‡•ç‡§ß‡§§
‡§ú‡§∞ VPC ‡§ö‡§æ ‡§∏‡§Ç‡§¶‡§∞‡•ç‡§≠ EC2 ‡§Æ‡§ß‡•ç‡§Ø‡•á ‡§¶‡§ø‡§≤‡§æ ‡§Ö‡§∏‡•á‡§≤, ‡§§‡§∞ Terraform ‡§Ü‡§™‡•ã‡§Ü‡§™ ‡§Ø‡•ã‡§ó‡•ç‡§Ø ‡§ï‡•ç‡§∞‡§Æ‡§æ‡§®‡•á ‡§∏‡§Ç‡§∏‡§æ‡§ß‡§®‡•á ‡§§‡§Ø‡§æ‡§∞ ‡§ï‡§∞‡§§‡•ã.


resource "aws_vpc" "my_vpc" {
  cidr_block = "10.0.0.0/16"
}

resource "aws_subnet" "my_subnet" {
  vpc_id     = aws_vpc.my_vpc.id  # VPC ‡§Ü‡§ß‡•Ä ‡§§‡§Ø‡§æ‡§∞ ‡§π‡•ã‡§à‡§≤
  cidr_block = "10.0.1.0/24"
}

resource "aws_instance" "my_instance" {
  ami           = "ami-0abcdef1234567890"
  instance_type = "t2.micro"
  subnet_id     = aws_subnet.my_subnet.id  # Subnet ‡§Ü‡§ß‡•Ä ‡§§‡§Ø‡§æ‡§∞ ‡§ù‡§æ‡§≤‡•ç‡§Ø‡§æ‡§µ‡§∞‡§ö EC2 ‡§∏‡•Å‡§∞‡•Ç ‡§π‡•ã‡§à‡§≤
}
‚úîÔ∏è Terraform ‡§Ü‡§ß‡•Ä VPC ‡§Ü‡§£‡§ø Subnet ‡§§‡§Ø‡§æ‡§∞ ‡§ï‡§∞‡•á‡§≤ ‡§Ü‡§£‡§ø ‡§Æ‡§ó EC2 ‡§á‡§Ç‡§∏‡•ç‡§ü‡§®‡•ç‡§∏ ‡§∏‡•Å‡§∞‡•Ç ‡§ï‡§∞‡•á‡§≤.

2Ô∏è‚É£ ‡§•‡•á‡§ü ‡§Ö‡§µ‡§≤‡§Ç‡§¨‡§ø‡§§‡•ç‡§µ (depends_on) ‚Äì ‡§ú‡§∞ ‡§•‡•á‡§ü ‡§∏‡§Ç‡§¶‡§∞‡•ç‡§≠ ‡§®‡§∏‡•á‡§≤ ‡§§‡§∞
‡§ï‡§ß‡•Ä ‡§ï‡§ß‡•Ä EC2 ‡§≤‡§æ VPC ‡§ö‡•Ä ‡§•‡•á‡§ü ‡§≤‡§ø‡§Ç‡§ï ‡§≤‡§æ‡§ó‡§§ ‡§®‡§æ‡§π‡•Ä, ‡§Ö‡§∂‡§æ‡§µ‡•á‡§≥‡•Ä depends_on ‡§µ‡§æ‡§™‡§∞‡•Ç‡§® ‡§ï‡•ç‡§∞‡§Æ ‡§∏‡•Å‡§®‡§ø‡§∂‡•ç‡§ö‡§ø‡§§ ‡§ï‡§∞‡•Ç ‡§∂‡§ï‡§§‡•ã.

hcl
Copy
Edit
resource "aws_instance" "my_instance" {
  ami           = "ami-0abcdef1234567890"
  instance_type = "t2.micro"
  
  depends_on = [aws_vpc.my_vpc]  # EC2 ‡§∏‡•Å‡§∞‡•Ç ‡§π‡•ã‡§£‡•ç‡§Ø‡§æ‡§Ü‡§ß‡•Ä VPC ‡§§‡§Ø‡§æ‡§∞ ‡§π‡•ã‡§à‡§≤
}
‚úîÔ∏è VPC ‡§§‡§Ø‡§æ‡§∞ ‡§ù‡§æ‡§≤‡•ç‡§Ø‡§æ‡§∂‡§ø‡§µ‡§æ‡§Ø EC2 ‡§á‡§Ç‡§∏‡•ç‡§ü‡§®‡•ç‡§∏ ‡§∏‡•Å‡§∞‡•Ç ‡§π‡•ã‡§£‡§æ‡§∞ ‡§®‡§æ‡§π‡•Ä.

üîπ ‡§®‡§ø‡§∑‡•ç‡§ï‡§∞‡•ç‡§∑
‚úÖ ‡§•‡•á‡§ü ‡§∏‡§Ç‡§¶‡§∞‡•ç‡§≠ (Implicit Dependency) ‡§µ‡§æ‡§™‡§∞‡§£‡•á ‡§∏‡§∞‡•ç‡§µ‡•ã‡§§‡•ç‡§§‡§Æ, ‡§ï‡§æ‡§∞‡§£ Terraform ‡§∏‡•ç‡§µ‡§Ø‡§Ç‡§ö‡§≤‡§ø‡§§‡§∞‡§ø‡§§‡•ç‡§Ø‡§æ ‡§ï‡•ç‡§∞‡§Æ ‡§†‡§∞‡§µ‡§§‡•ã.
‚úÖ depends_on ‡§µ‡§æ‡§™‡§∞‡§æ, ‡§ú‡§∞ ‡§•‡•á‡§ü ‡§∏‡§Ç‡§¶‡§∞‡•ç‡§≠ ‡§®‡§∏‡•á‡§≤ ‡§™‡§£ VPC ‡§Ü‡§ß‡•Ä ‡§§‡§Ø‡§æ‡§∞ ‡§π‡•ã‡§£‡•á ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï ‡§Ö‡§∏‡•á‡§≤. üöÄ

‚úÖ Use implicit dependencies (referencing another resource) whenever possible.
‚úÖ Use depends_on if no direct reference exists but an order must be enforced. üöÄ
---------------------------------------------------------------------------------------------------------------------------------------------
27. What is Ansible, and why do we use it ?

===========  
Broadridge:
=========== 

What is CI ?
---------------------------------------------------------------------------------------------------------------------------------------------------------------
Why we use jenkins If we can do everything on local ? 

‚úÖ 1. Automation & Continuous Integration ‚Äì No need for manual builds/tests.
‚úÖ 2. Centralized CI/CD Pipeline ‚Äì Ensures consistency across teams.
‚úÖ 3. Scalability ‚Äì Runs on multiple agents (remote nodes).
‚úÖ 4. Scheduled & Triggered Builds ‚Äì Automates based on commits or schedules.
‚úÖ 5. Parallel Execution ‚Äì Reduces build time with multiple machines.
‚úÖ 6. Security & Access Control ‚Äì Role-based access, logs, and approvals.
‚úÖ 7. Artifact Storage ‚Äì Integrates with AWS S3, Nexus, and Artifactory.
‚úÖ 8. Tool & Cloud Integrations ‚Äì Works with Docker, Kubernetes, Terraform, etc.
----------------------------------------------------------------------------------------------------------------------------------------------------------------
Let's takes example I have installed application in EC2 instance how you forward the log to the cloud watch ?

### **Forwarding EC2 Logs to CloudWatch**  

To send logs from an **EC2 instance** to **AWS CloudWatch**, follow these steps:  

---

### **1Ô∏è‚É£ Install & Configure CloudWatch Agent**
1. **Install the CloudWatch Agent** on the EC2 instance:  
   ```sh
   sudo yum install -y amazon-cloudwatch-agent  # Amazon Linux
   sudo apt-get install -y amazon-cloudwatch-agent  # Ubuntu/Debian
   ```

2. **Configure the CloudWatch Agent:**  
   ```sh
   sudo /opt/aws/amazon-cloudwatch-agent/bin/amazon-cloudwatch-agent-config-wizard
   ```
   - Select **logs** and specify the log file path (e.g., `/var/log/myapp.log`).  
   - Choose **log group** name in CloudWatch.  

3. **Start the CloudWatch Agent:**  
   ```sh
   sudo systemctl start amazon-cloudwatch-agent
   sudo systemctl enable amazon-cloudwatch-agent
   ```

---

### **2Ô∏è‚É£ Manually Configure CloudWatch Logs (Optional)**
Instead of using the wizard, create a **CloudWatch agent config file**:

```json
{
  "logs": {
    "logs_collected": {
      "files": {
        "collect_list": [
          {
            "file_path": "/var/log/myapp.log",
            "log_group_name": "MyAppLogs",
            "log_stream_name": "{instance_id}",
            "timestamp_format": "%Y-%m-%d %H:%M:%S"
          }
        ]
      }
    }
  }
}
```

1. **Save the file as** `/opt/aws/amazon-cloudwatch-agent/bin/config.json`  
2. **Apply the config and restart the agent:**  
   ```sh
   sudo /opt/aws/amazon-cloudwatch-agent/bin/amazon-cloudwatch-agent-ctl -a fetch-config -m ec2 -c file:/opt/aws/amazon-cloudwatch-agent/bin/config.json -s
   ```

---

### **3Ô∏è‚É£ Verify Logs in CloudWatch**
Go to **AWS Console ‚Üí CloudWatch ‚Üí Log Groups** and check if the logs are streaming.  

‚úÖ **Now your EC2 application logs are being forwarded to AWS CloudWatch!** üöÄ
--------------------------------------------------------------------------------------------------------------------------------------------------------------------
Write replicaset manifest files ?
Write a python programme which retrives ebs volume from AWS ?
--------------------------------------------------------------------------------------------------------------------------------------------------------------------
How to take backup of EC2 instance through automation ?
#!/bin/bash

# Define variables
INSTANCE_ID="i-xxxxxxxxxxxxxxxxx"  # Replace with your EC2 ID
DATE=$(date +%Y-%m-%d-%H-%M-%S)
DESCRIPTION="Backup-$INSTANCE_ID-$DATE"

# Get Volume ID
VOLUME_ID=$(aws ec2 describe-instances --instance-ids $INSTANCE_ID --query "Reservations[0].Instances[0].BlockDeviceMappings[0].Ebs.VolumeId" --output text)

# Create snapshot
aws ec2 create-snapshot --volume-id $VOLUME_ID --description "$DESCRIPTION"

echo "Snapshot created for EC2 instance $INSTANCE_ID"
---------------------------------------------------------------------------------------------------------------------------------------------------------------
write manifest file for replicaset take replicaset number as 5 ? 
Replicaset and Deployment diff ?
How to send image to ECR on specific repository ? ---> docker push <account-id>.dkr.ecr.<region>.(link unavailable)<repository-name>:<image-tag>
End to end flow of EFK ?
Could tell me if I want install fluentbit on Kubernetes Cluster how can you do it ?
What are jenkins plugins you are using in your projects ?
What is plugins ?
-------------------------------------------------------------------------------------------------------------------------------------------------------
Write a script to reverse the string ?

#!/bin/bash

# Read input
read -p "Enter a string: " str

# Reverse the string using `rev` command
echo "Reversed: $(echo "$str" | rev)"

Enter a string: hello
Reversed: olleh
------------------------------------------------------------------------------------------------------------------------------------------------------
Write a Python script to find concurrency in mentioned array (this is soham) ?
-----------------------------------------------------------------------------------------------------------------------------------------------------
Write a Python script to find out large number from a list ( list = [12,14,16,18] ) ?

#!/bin/bash
numbers=(12 14 16 18)
max=${numbers[0]}

for num in "${numbers[@]}"; do
  [ "$num" -gt "$max" ] && max=$num
done

echo "Largest: $max"

----------------------------------------------------------------------------------------------------------------------------------------------------
================
Maruti Tech Labs
================

Docker I want to run docker image how will you that which os will it run on like windows or linux 
docker networking types
------------------------------------------------------------------------------------------------------------------------------
two containers are running on default networking can they talk with each other ?
yes, but if network is different then it will not communicate
------------------------------------------------------------------------------------------------------------------------------

vpc end points ?
RDS 
cloudfront - 
route53 - policy types and how we check health check ?

------------------------------------------------------------------------------------------------------------------------------------------
Let's take there is an person who created pods in kubernetes without creating deployment files and labels and now you want check
‡§è‡§ï‡§æ ‡§µ‡•ç‡§Ø‡§ï‡•ç‡§§‡•Ä‡§®‡•á Kubernetes ‡§Æ‡§ß‡•ç‡§Ø‡•á ‡§™‡•â‡§°‡•ç‡§∏ ‡§§‡§Ø‡§æ‡§∞ ‡§ï‡•á‡§≤‡•á, ‡§™‡§£ ‡§ï‡•ã‡§£‡§§‡•á‡§π‡•Ä Deployment ‡§´‡§æ‡§Ø‡§≤‡•Ä ‡§Ü‡§£‡§ø ‡§≤‡•á‡§¨‡§≤‡•ç‡§∏ ‡§µ‡§æ‡§™‡§∞‡§≤‡•á ‡§®‡§æ‡§π‡•Ä‡§§. ‡§§‡•Å‡§Æ‡•ç‡§π‡§æ‡§≤‡§æ ‡§π‡•á ‡§§‡§™‡§æ‡§∏‡§æ‡§Ø‡§ö‡•á ‡§Ö‡§∏‡•á‡§≤, ‡§§‡§∞ ‡§ï‡•ã‡§£‡§§‡•á ‡§Ü‡§¶‡•á‡§∂ ‡§µ‡§æ‡§™‡§∞‡§æ‡§≤?

kubectl get pods -o wide
kubectl get pods --show-labels
kubectl get pods -A --field-selector metadata.ownerReferences[].kind!=ReplicaSet
üîπ ‡§Ø‡§æ‡§®‡•á ‡§Ö‡§∏‡•á ‡§™‡•â‡§°‡•ç‡§∏ ‡§¶‡§ø‡§∏‡§§‡•Ä‡§≤ ‡§ú‡•á ‡§ï‡•ã‡§£‡§§‡•ç‡§Ø‡§æ‡§π‡•Ä Deployment ‡§ï‡§ø‡§Ç‡§µ‡§æ ReplicaSet ‡§¶‡•ç‡§µ‡§æ‡§∞‡•á ‡§µ‡•ç‡§Ø‡§µ‡§∏‡•ç‡§•‡§æ‡§™‡§ø‡§§ ‡§ï‡•á‡§≤‡•á ‡§ú‡§æ‡§§ ‡§®‡§æ‡§π‡•Ä‡§§.

------------------------------------------------------------------------------------------------------------------------------------------------------
it its created by default lables now 
Want change label how can you do that ? 
kubectl get pod <pod-name> --show-labels
kubectl label pod <pod-name> <label-key>=<label-value> --overwrite
kubectl label pod my-pod environment=production --overwrite

-----------------------------------------------------------------------------------------------------------------------------------------------------------
You have two applications running as two pods on two different nodes in a Kubernetes cluster.
Now, you want to drain these pods from one node and make both pods run on a single node.

kubectl get pods -o wide
üîπ This will show the node name where each pod is running.

kubectl cordon <node-name>
üîπ This marks the node as unschedulable so that new pods will not be scheduled on it.

kubectl drain <node-name> --ignore-daemonsets --delete-emptydir-data
üîπ This command evicts all running pods (except DaemonSet pods) from the node.

üö® Note: If pods are managed by a Deployment, ReplicaSet, or StatefulSet, Kubernetes will automatically reschedule them.

Step 4: Ensure Pods Run on a Specific Node
To force the pods to run on a single node, apply node affinity or a nodeSelector in the pod‚Äôs YAML:
Option 1: Using nodeSelector
Edit the deployment YAML and add:

spec:
  nodeSelector:
    kubernetes.io/hostname: <preferred-node-name>






---------------------------------------------------------------------------------------------------------------------------------------------------------------
If I have different environments like dev and staging, and I use Terraform modules for each resource, 
can I run multiple EC2 instances with duplication using Terraform?

Yes! You can duplicate EC2 instances using count or for_each inside Terraform modules.
module "ec2_instance" {
  source  = "./modules/ec2"  # Path to EC2 module
  count   = 2  # Create 2 identical instances
  env     = "dev"
}
Use count if you want identical EC2 instances.

Use for_each if you want customized instances with different configurations.



--------------------------------------------------------------------------------------------------------------------------------------------------------------
What is null resource in terraform ?
A null_resource in Terraform is like a dummy resource that does not create anything but is used to run scripts or trigger actions when something changes.

1Ô∏è‚É£ Run Scripts Without Creating Resources

You can execute a script locally or on a remote server when running terraform apply.

2Ô∏è‚É£ Trigger Actions Based on Changes

If a resource changes, null_resource can detect it and run a command.

3Ô∏è‚É£ Work With Provisioners

Used with local-exec or remote-exec to run custom scripts.

resource "null_resource" "example" {
  provisioner "local-exec" {
    command = "echo 'Terraform executed this script!'"
  }
}
When you run terraform apply, it prints the message but does not create any infrastructure.
----------------------------------------------------------------------------------------------------------------------------------------------------

========== 
Cloudraft
==========

How do you store secrets in Kubernetes (e.g., using Secret Manager), and how does ArgoCD detect that a particular secret is not synced (i.e., not pushed)?


==========

I  have deployed my application on ec2 instance and it's giving me 500 when user trying acces it via url name 

Docker
cmd and entrypoint

-------------------------------------------------------------------------------------------------------------------------------------------
how you check the health of docker container
docker ps
docker inspect --format='{{.State.Health.Status}}' container-name
docker logs container-name --tail 50
docker exec container-name healthcheck-command
-----------------------------------------------------------------------------------------------------------------------------------------------


have created mysql data base application by using statefulset now coz of

-----------------------------------------------------------------------------------------------------------------------------------------------------
que. If a Kubernetes Pod is in a CrashLoopBackOff state and later changes to the Ready state, will the Pod name change?
ans    No, the Pod name will remain the same if it recovers from CrashLoopBackOff to Ready.
       The Kubernetes kubelet will restart the same Pod without changing its name.

       If the Pod is managed by a Deployment or ReplicaSet, it will only get a new name if the Pod is deleted and recreated.

      In a StatefulSet, even if the Pod is deleted and recreated, the name will stay the same (e.g., mysql-0).

      Only if the Pod is completely replaced (e.g., via a new Deployment rollout) will the name change.

üî• When Does a Pod Name Change?
1Ô∏è‚É£ If the Pod is deleted and recreated (manually or by the Deployment).
2Ô∏è‚É£ If a new rollout happens (e.g., updating the Deployment).
3Ô∏è‚É£ If the Pod is managed by a ReplicaSet and it replaces the old Pod.

---------------------------------------------------------------------------------------------------------------------------------------------------------------
terraform there is an ebs there are different env dev env and staging env now i am doing terraform plan but changing the tag of that ebs how will you fix it 
‡§§‡•Å‡§Æ‡•ç‡§π‡•Ä Terraform plan ‡§ö‡§æ‡§≤‡§µ‡§§ ‡§Ö‡§∏‡§§‡§æ‡§®‡§æ ‡§ú‡§∞ EBS ‡§µ‡•ç‡§π‡•â‡§≤‡•ç‡§Ø‡•Ç‡§Æ‡§ö‡§æ tag ‡§¨‡§¶‡§≤‡§≤‡§æ ‡§Ö‡§∏‡•á‡§≤ ‡§Ü‡§£‡§ø Terraform ‡§§‡•ç‡§Ø‡§æ‡§≤‡§æ recreate (delete & create) ‡§ï‡§∞‡§æ‡§Ø‡§≤‡§æ ‡§®‡§ø‡§ò‡§§ ‡§Ö‡§∏‡•á‡§≤, ‡§§‡§∞ ‡§ñ‡§æ‡§≤‡•Ä‡§≤ ‡§â‡§™‡§æ‡§Ø ‡§µ‡§æ‡§™‡§∞‡•Ç ‡§∂‡§ï‡§§‡§æ.

ans.  To fix this issue, ensure that the EBS volume uses lifecycle { ignore_changes = ["tags"] } to prevent unnecessary replacement when only the tag is changed.
--------------------------------------------------------------------------------------------------------------------------------------------------------------------

I want to know the the ip of my mysql container without running exec command in docker as well in k8s
docker inspect
kubectl get pod -o wide | grep mysql
kubectl get svc mysql-service-name -o jsonpath='{.spec.clusterIP}'
-------------------------------------------------------------------------------------------------------------------------------------------------------
 Answer: Restrict AWS Usage to Only 2 Regions
To allow AWS services only in 2 regions and restrict all others, use Service Control Policies (SCPs) in AWS Organizations.

‚úÖ Solution: Create an SCP Policy
1Ô∏è‚É£ Go to AWS Organizations ‚Üí Service Control Policies
2Ô∏è‚É£ Create a new SCP with this JSON:

json
Copy
Edit
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Deny",
      "Action": "*",
      "Resource": "*",
      "Condition": {
        "StringNotEquals": {
          "aws:RequestedRegion": ["us-east-1", "us-west-2"]
        }
      }
    }
  ]
}
üîπ This denies all actions outside us-east-1 and us-west-2.
üîπ Attach this SCP to the required OU (Organizational Unit) or AWS accounts.

‚úÖ Result: AWS services will only work in us-east-1 and us-west-2, while all other regions are restricted.
-------------------------------------------------------------------------------------------------------------------------------------------------


üîπ Answer: Upgrade EC2 Instance Type (T2 ‚Üí M4)
To upgrade an EC2 instance from t2 to m4, follow these steps:

‚úÖ Option 1: Using AWS Console
1Ô∏è‚É£ Stop the EC2 instance (Instance State ‚Üí Stop).
2Ô∏è‚É£ Go to Instance Settings ‚Üí Change Instance Type.
3Ô∏è‚É£ Select the new instance type (e.g., m4.large).
4Ô∏è‚É£ Click Apply and Start the instance.
 Best Practice: Plan maintenance downtime if using a single instance. If running multiple instances, use Auto Scaling and Load Balancing to avoid downtime.



