maneged and self hosted cluster
maeged - controil plain by cloud and data palan by ourself
self hosted - both maneged by ourself
--------------------------------------------------------------------

Advanced Kubernetes Scheduling
This repository demonstrates advanced scheduling techniques in Kubernetes, including Node Selector, Node Affinity, Taints & Tolerations,
and Pod Affinity & Anti-Affinity. These techniques allow you to fine-tune how your workloads are distributed across your cluster, ensuring optimal performance and resource utilization.

Topics Covered
1. Node Selector
Node Selector is a simple way to ensure that your pods run on specific nodes by assigning labels. This is useful when you have node
s with special hardware or software configurations and you want certain workloads to run only on those nodes.

Example Use Case: Targeting a node with high-performance CPUs for compute-intensive tasks.
# Label a node with a custom label
kubectl label node <node-name> high-perf-cpu=yes

# Deploy a pod targeting the node with the specified label
kubectl apply -f <your-deployment-file>.yaml

# Verify that the pod is running on the correct node
kubectl get pods -o wide --no-headers | awk -F" " '{print $1, $8}'

2. Node Affinity
Node Affinity allows more complex scheduling decisions based on node labels. Unlike Node Selector, Node Affinity supports 
multiple label expressions and can differentiate between preferred and required conditions.

Example Use Case: Ensuring that pods are deployed only on nodes with specific environmental settings or hardware.
# Label nodes with different environment labels
kubectl label node <node1-id> env=one
kubectl label node <node2-id> env=two
kubectl label node <node3-id> env=three

# Deploy a workload with Node Affinity rules
kubectl apply -f <your-deployment-file>.yaml

# Scale the deployment to observe how pods are distributed

kubectl scale deployment <deployment-name> --replicas=8


3. Taints & Tolerations

Taints are applied to nodes to prevent pods that don't tolerate the taint from being scheduled on them. 
Tolerations are applied to pods to allow them to be scheduled on tainted nodes. This feature is essential for keeping certain workloads 
separate or ensuring critical workloads are not disrupted.

Example Use Case: Ensuring that only specific pods can run on a node reserved for special tasks.
# Taint nodes to control scheduling
kubectl taint node <node-id> high-cpu=yes:NoSchedule
kubectl taint node <node-id> med-cpu=yes:NoExecute

# Describe the node to see its taints
kubectl describe node <node-id> | grep -i high

# Deploy a pod to see if it gets scheduled based on tolerations
kubectl apply -f <your-deployment-file>.yaml

# Remove taints from nodes if needed
kubectl taint node <node-id> high-cpu-
kubectl taint node <node-id> med-cpu-


4. Pod Affinity & Anti-Affinity
Pod Affinity allows you to schedule pods together on the same node, while Pod Anti-Affinity ensures that pods are placed on separate nodes. 
This is useful for reducing latency between pods or ensuring high availability by spreading pods across nodes.

Example Use Case: Grouping frontend and backend pods together to reduce network latency or ensuring that replicas of the same 
service are spread out to avoid single points of failure.
# Use pod affinity or anti-affinity in your deployment YAML
kubectl apply -f <your-deployment-file>.yaml

# Scale the deployment and observe the behavior
kubectl scale deployment <deployment-name> --replicas=2

# Drain a node to see how pods are rescheduled
kubectl drain <node-id>
kubectl uncordon <node-id>
Commands Overview
Hereâ€™s a summary of the key commands used for the topics covered:

# Label a node
kubectl label node <node-name> high-perf-cpu=yes

# Apply a deployment file
kubectl apply -f <your-deployment-file>.yaml

# Verify pod placement
kubectl get pods -o wide --no-headers | awk -F" " '{print $1, $8}'

# Label nodes for Node Affinity
kubectl label node <node1-id> env=one
kubectl label node <node2-id> env=two
kubectl label node <node3-id> env=three

# Scale a deployment
kubectl scale deployment <deployment-name> --replicas=8

# Taint nodes
kubectl taint node <node-id> high-cpu=yes:NoSchedule
kubectl taint node <node-id> med-cpu=yes:NoExecute

# Remove taints from nodes
kubectl taint node <node-id> high-cpu-
kubectl taint node <node-id> med-cpu-

# Drain and uncordon a node
kubectl drain <node-id>
kubectl uncordon <node-id>
Conclusion
This repository provides practical examples and commands to help you understand and implement advanced scheduling techniques in Kubernetes. 
By mastering these concepts, you can ensure that your applications run efficiently and reliably in a Kubernetes environment.





----------------------------------------------------------------------------------------------------------------------------------------------------------------
node selctor and node affinity diff
in node selector we can pass single expression heare
but in node affinity we can pass multiple matchexpression heare          --------vimp
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------
pod affinity and anipod affinity

user is trying to application - first request heating to FE - with the help of ingress - FE is going to BE - BE is going DB
it will give the info - but u will see the lot of latancy heare to avoid that we used pod affinity 
we will make gropu of FE AND BE , DB TO AVOID latency
next time customer is trying to access - route will be tranfer FE-BE-DB  
--------------------------------------------------------------------------------------------------------------------------------------------------------
antipod
means just like deamonset -but not puerly - it make sure that no multiple pod on the same node | sprading pod across multiple node
--------------------------------------------------------------------------------------------------------------------------------------



node selector by WORKER NODE id

 nodeSelector:
        kubernetes.io/hostname: i-00a968443bbbdd1cf


apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: myapp01
  name: myapp01
spec:
  replicas: 3
  selector:
    matchLabels:
      app: myapp01
  template:
    metadata:
      labels:
        app: myapp01
    spec:
      containers:
      - image: kiran2361993/kubegame:v2
        name: kubegame
      nodeSelector:
        kubernetes.io/hostname: i-00a968443bbbdd1cf

apply it
ku gets pods
tych node vr pod crete hotil

 ku scale deployment nyapp0l --roplicas 10
scale kelyavr pn tych node vr hotil

delete all
----------------------------------------------------------------------------------


node selector by label

kubectl label node i-08cb4fadSc2fd467e high-perf-cpu=yes
kubectl label node i-0d255ef313a497963 low-perf-cpu=yes
kubectl label node i-0dcf19a32f70443af low-perf-cpu=yes


 nodeSelector:
        high-perf-cpu: "yes"


first lable dyv lagel

kubectl label node i-08cb4fadSc2fd467e high-perf-cpu=yes
kubectl label node i-0d255ef313a497963 low-perf-cpu=yes
kubectl label node i-0dcf19a32f70443af low-perf-cpu=yes

kubectl describe node i-08cb4fad5c2fd467e | grep -i high
kubectl describe node i-0d255ef313a497963 | grep -i med
kubectl describe node i-0dcf19a32f70443af | grep -i low


apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: myapp02
  name: myapp02
spec:
  replicas: 4
  selector:
    matchLabels:
      app: myapp02
  template:
    metadata:
      labels:
        app: myapp02
    spec:
      containers:
      - image: kiran2361993/kubegame:v2
        name: kubegame
      nodeSelector:
        high-perf-cpu: "yes"

apply it
ku get pods -o wide
2 node la 1 ch same lable ahe

ku scale deployment myapp02 --replicas 10
delete all
------------------------------------------------------------------------------------------------------------------
node affinity
reqired
prefered


reqired

kubectl label node i-08cb4fad5c2fd467e env=one
kubectl label node i-0d255ef313a497963 env=two
kubectl label node i-0dcf19a32f70443af env=three

apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    run: required-hard
  name: required-hard
spec:
  replicas: 4
  selector:
    matchLabels:
      run: required-hard
  template:
    metadata:
      labels:
        run: required-hard
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: env
                operator: In
                values:
                - one
                - two
      containers:
      - image: nginx:latest
        name: required-hard

apply it
ku get pods -o wide --no-headers

hya 2 vr depoly honar 
node i-08cb4fad5c2fd467e env=one
node i-0d255ef313a497963 env=two
------------------------------------------------------------
prefered

apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    run: preferred-soft
  name: preferred-soft
spec:
  replicas: 4
  selector:
    matchLabels:
      run: preferred-soft
  template:
    metadata:
      labels:
        run: preferred-soft
    spec:
      affinity:
        nodeAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 40
            preference:
              matchExpressions:
              - key: env
                operator: In
                values:
                - one
          - weight: 30
            preference:
              matchExpressions:
              - key: env
                operator: In
                values:
                - two
          - weight: 30
            preference:
              matchExpressions:
              - key: env
                operator: In
                values:
                - three
      containers:
      - image: nginx
        name: deploy01

1. 3 la 10 privority dych
2. 2 and 3rd same same 30 privority - equel ch ghet
---------------------------------------------------------------------------------------------------------------

taint and  tolration





































